This file is dedicated for the ordinal analysis of SALES (5/4/21)

```{r}

SALES <- read.csv("SALES.csv")
```

#Loading Libraries


```{r}
library(tidyverse) # For data wrangling
library(ggplot2) # for graphing / figures - mostly histograms/ppplots here
library(pastecs) # Needed to run normality tests
library(car) # Needed to run Levene test
library(lsr) # Navarro package for running psychology tests
library(psych) # for key psychology stats
library(effects) # Effects package, needed for the estimated means, includes lower/upper 95% conf limits
library(ggpubr)
library(boot); library(ggm); library(ggplot2); library(Hmisc);
library(polycor)
library(lavaan)
library(dplyr) 
library(tidyr)
options(scipen=99) # This is to indicate how many digits after the decimal, this one is for 2 digits, but can be changed
```


#Intro to SALES survey

Q7-Q14	SE (8 questions)
Q15-Q22	TV (8 questions)
Q23-Q32	MG (8 questions), Question 30 is missing. 
Notes: Questions 26 and 31 are repeated
Questions 24 and 29 are repeated

SALES 2 has no X, and doest not have the total coloumn. 
```{r}
SALES2 <-select(SALES, ID:Q32)
```

```{r}
library(psych)
des <- describe(SALES2)
knitr::kable(des[,c("min", "max", "mean", "median", "skew", "kurtosis")], main = "Data Summary")
```

#Normality asssumptions

```{r}
hist(SALES2)
```

```{r}
hist(SALES$total)
```

```{r}
describe(SALES2)
```


#Pearson correlations

```{r}
pear_cor = cor(SALES2)
cor.plot(pear_cor, numbers=T, upper=FALSE, main = "SALES_Pearson Correlation", show.legend = FALSE)
```


#Polychor correlations

```{r}
SALES2 = select(SALES2, Q07:Q32) #selecting the data for correlations
poly_cor = polychoric(SALES2)
rho = poly_cor$rho
save(rho, file = "polychoric.doc")
### Thresholds/Scaling results
poly_cor$tau
```

Plotting correlations

```{r}
Polychor_plot <- cor.plot(poly_cor$rho, numbers=T, upper=FALSE, main = "SALES_Polychoric Correlation", show.legend = FALSE)
```

Comparing the differneces between the two types of correlations

```{r}
diff = (poly_cor$rho - pear_cor)*((pear_cor>=0)*2-1)

cor.plot(diff, numbers=T, upper=FALSE, diag=FALSE)
```

#Ordinal CFA

```{r}
load("polychoric")
# Scree plot
fa.parallel(rho, n.obs=394, fm="pa", fa="fa", main = "Scree Plot")
```


Polymodel 1 using ML as an estimator
```{r}
poly_model = fa(SALES2, nfactor=5, cor="poly", fm="mle", rotate = "none")
save(poly_model, file = "poly_model_ML.doc")
poly_model$loadings
```
```{r}
sink("polymodel_ML.doc")
print(fa(SALES2, nfactor=5, cor="poly", fm="mle", rotate = "none"))
sink()
```

```{r}
fa.diagram(poly_model2)
```
Polymodel 2 using DWLS as an estimator
```{r}
poly_model2 = fa(SALES2, nfactor=3, cor="poly", fm="ULS", rotate = "none")
save(poly_model, file = "poly_model_DWLS.doc")
poly_model2$loadings
```
Exporting output
```{r}
sink("poly_model_DWLS.doc")
print(fa(SALES2, nfactor=5, cor="poly", fm="ULS", rotate = "none"))
sink()
```


```{r}
sink("poly_model_DWLS_3FAs.doc")
print(fa(SALES2, nfactor=3, cor="poly", fm="ULS", rotate = "none"))
sink()
```

#CFA 

```{r}
latents.model_s <- 'SelfEfficacy =~ Q08 +  Q07 + Q09 + Q10 + Q11 + Q12 + Q13 + Q14
TaskValue =~ Q18 + Q15 + Q16 + Q17 + Q19 + Q20 + Q21 + Q22
MasteryGoals =~ Q24 + Q23 + Q25 + Q26 + Q27 + Q28 + Q29 + Q31 + Q32'
```

Run CFA model

```{r}
SALESfit <- cfa(latents.model_s,data = SALES2, ordered= TRUE, estimator = "DWLS") #ordered = true means that the variables are ordered categoricals
#to view summary of the fit
partable(SALESfit) # to have the summary of parameters converted to a dataframe
vartable(SALESfit) # to have the summary of variables converted to a dataframe
parameterestimates(SALESfit)
summary (SALESfit) #parameterEstimates() includes the estimates, standard errors, z value, p value, and 95% CIs for all model parameters.
```
To see a summary of the tests and esimtates of the model

```{r}
summary(SALESfit,fit.measures = TRUE,standardized=TRUE)
```

SInce the values are categorical, one would need to youâ€™ll want to look at expected vs. observed counts in each level instead of residual correlations. You can get that with lavTables(fit).

```{r}
lavTables(SALESfit)
```


```{r}
cor_table <- residuals(SALESfit, type = "cor")

cor_table[upper.tri(cor_table)] <- NA # erase the upper triangle


kable(cor_table, digits=2) # makes a nice table and rounds everyhing to 2 digits
```



Putting the data into a nice table (using knitR)
```{r}
parameterEstimates(SALESfit, standardized=TRUE) %>% 
  filter(op == "=~") %>% 
  select('Latent Factor'=lhs, Indicator=rhs, B=est, SE=se, Z=z, 'p-value'=pvalue, Beta=std.all) %>%
  kable(digits = 3, format="pandoc", caption="Factor Loadings")
```

```{r}
sink("SALESfit_DWLS.doc")
print(summary(SALESfit,fit.measures = TRUE))
sink()
```


