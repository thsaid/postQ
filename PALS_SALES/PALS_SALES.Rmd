---
title: "PALS_SALES"
author: "Tamer Said"
date: "05/01/2021"
output: html_document
---
#PALS Questions

Summary of the PALS Questions and their factors
Mastery Goals (MG): PQ01:PQ05
Performance Approach Goals (PAPG) Q06:Q10
Performance Avoidance Goals (PAVG) Q11:Q14
Self-efficacy (SE) PQ15:PQ19

#Intro to SALES survey

Self-efficacy: SQ7-SQ14	SE (8 questions)
Task Value: Q15-Q22	TV (8 questions)
Mastery Goals Q23-Q32	MG (8 questions), Question 30 is missing. 
Notes: Questions 26 and 31 are repeated
Questions 24 and 29 are repeated


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

Loading libraries

```{r}
library(tidyverse)
```

Loading SALES files

```{r}
SALES <- read.csv("SALES.csv")
```
Renaming the Questions using S, to avoid confusion with the SALES when merged together

```{r}
SALES <- rename(SALES, SQ07=Q07, SQ08=Q08, SQ09=Q09, SQ10=Q10, SQ11=Q11, SQ12=Q12, SQ13=Q13, SQ14=Q14, SQ15=Q15, SQ16=Q16, SQ17=Q17, SQ18=Q18, SQ19=Q19, SQ20=Q20, SQ21=Q21, SQ22=Q22, SQ23=Q23, SQ24=Q24, SQ25=Q25, SQ26=Q26, SQ27=Q27, SQ28=Q28, SQ29=Q29, SQ31=Q31, SQ32=Q32)
```

Loading PALS files
```{r}
PALS <- read.csv("PALS.csv")
PALS <- rename(PALS, PQ01=Q01, PQ02=Q02, PQ03=Q03, PQ04=Q04, PQ05=Q05, PQ06=Q06, PQ07=Q07, PQ08=Q08, PQ09=Q09, PQ10=Q10, PQ11=Q11, PQ12=Q12, PQ13=Q13, PQ14=Q14, PQ15=Q15, PQ16=Q16, PQ17=Q17, PQ18=Q18, PQ19=Q19)

```

Joining the two tables together PALS & SALES
```{r}
PALS_SALES <- inner_join(x = PALS, y = SALES, by= "ID")

```

Saving the file

```{r}
write.csv(PALS_SALES, "PALS_SALES.csv")
```

Selecting relevant coloumns for the matrix

```{r}
PALS_SALES_filtered <- select(PALS_SALES, ID, Gender.x, Certificate,PQ01:PQ19, SQ07:SQ32)
```


After joining the two tables the total observations are 359 observations, (that's the total no. of participants who did the pre and post surveys)

#I will start with an EFA to see how these two instruments fit together

```{r}
#Installing packages and loading libraries


library(corpcor); library(GPArotation); library(psych)
library(boot); library(ggm); library(ggplot2); library(Hmisc);
library(polycor);library(lavaan)

```
Running correlations for the whole data frame. This command below excludes the missing values and those that are not numeric.
```{r}
cor(PALS_SALES_filtered[sapply(PALS_SALES_filtered, is.numeric)], use='pairwise')
```
Saving the correlation matrix to a variable

```{r}
P_Scorr <- cor(PALS_SALES_filtered[sapply(PALS_SALES_filtered, is.numeric)], use='pairwise')
```


Running Barlette test on the correlation matrix in prep for FA. The p value shall be less than 0.5.

A significant test tells us that the R-matrix is not an identity matrix(identity matrix is the case when variables are NOT related to each other and corr is zero); Therefore, if it is significant then it means that the correlations between variables are (overall) significantly different from zero, if Bartlettâ€™s test is significant then it is good news (Field, 2009)


```{r}
cortest.bartlett(P_Scorr, n=359)
```

Running KMO test for the degree of common variance (ideally, a score of 0.5 or higher is good). values close to 1 indicates that patterns of correlations are relatively compact and so factor analysis should yield distinct and reliable factors.

```{r}
KMO(P_Scorr)
```
The MSA score of 0.91 is a good indicator

#PCA:I have set the factors to 44, which is the number of the items. This is just an exploratory step

```{r}
pc44 <- principal(P_Scorr, nfactors = 44, rotate = "none")
pc44
```

SS loading: refer to sum of squared loadings
```{r}
pc44$values

```

This command allows to view the eigenvalues of each factor. 


Screeplot to determine the eigenvalues

```{r}
plot(pc44$values, type = "b")
```
#6 facotrs: trying out 6 factors

```{r}
factors_data_6 <- fa(r = P_Scorr, nfactors = 6)
factors_data_6
```

According to the output, only 5 factors had high loadings, factor 6 did not have any high loadings. After the 5th factor, the eigenvalues dropped from 2.75 to 0.8  Accordingly, I will try 5 factors only to see if there is a better outfit.
#5 factors model
```{r}
factors_data_5 <- fa(r = P_Scorr, nfactors = 5)
factors_data_5
```

#4 factors model

```{r}
factors_data_4 <- fa(r = P_Scorr, nfactors = 4)
factors_data_4
```
The scores for the 5 factor model, works better than the 4 factor model.

#Parallel analysis to identify the key factors needed

```{r}
fa.parallel(P_Scorr,n.obs =359,fa ="fa")
```

#Q: I am not sure how to save the output of my data

```{r}
write.table (factors_data_5, "PALS_SALES_factors.csv")
```

#CFA

#PALS Questions

Summary of the PALS Questions and their factors
Mastery Goals (MG): PQ01:PQ05
Performance Approach Goals (PAPG) Q06:Q10
Performance Avoidance Goals (PAVG) Q11:Q14
Self-efficacy (SE) PQ15:PQ19

#Intro to SALES survey

Self-efficacy: SQ7-SQ14	SE (8 questions)
Task Value: Q15-Q22	TV (8 questions)
Mastery Goals Q23-Q32	MG (8 questions), Question 30 is missing. 

Will run several CFA models to see how both tools fit together

#Model1: Treating Motivation as one factor

Let's start be defining the measurement model

```{r}
latents.model1 <- 'Motivation =~ PQ02 + PQ01  + PQ03 + PQ04 + PQ05 + PQ09 + PQ06 + PQ07 + PQ08 + PQ10 + PQ14 + PQ11 + PQ12 + PQ13 + PQ16 + PQ15 + PQ17 + PQ18 + PQ19 + SQ08 +  SQ07 + SQ09 + SQ10 + SQ11 + SQ12 + SQ13 + SQ14
+ SQ18 + SQ15 + SQ16 + SQ17 + SQ19 + SQ20 + SQ21 + SQ22
+ SQ24 + SQ23 + SQ25 + SQ26 + SQ27 + SQ28 + SQ29 + SQ31 + SQ32'

```

```{r}
PALS_SALESfit <- cfa(latents.model1, data =PALS_SALES)#standard fit
summary(PALS_SALESfit) #to view summary of the fit
partable(PALS_SALESfit) # to have the summary of parameters converted to a dataframe
vartable(PALS_SALESfit) # to have the summary of variables converted to a dataframe
parameterestimates(PALS_SALESfit) #parameterEstimates() includes the estimates, standard errors, z value, p value, and 95% CIs for all model parameters.
```
To see a summary of the tests and esimtates of the model

```{r}
summary(PALS_SALESfit,fit.measures = TRUE)
```

Model 1 fit indices:

User Model versus Baseline Model:

  Comparative Fit Index (CFI)                    0.471
  Tucker-Lewis Index (TLI)                       0.445
  
  Model is unacceptable
  
#Model 2:Treating each tool as a separate factor

```{r}
latents.model2 <- 'PALS =~ PQ02 + PQ01  + PQ03 + PQ04 + PQ05 + PQ09 + PQ06 + PQ07 + PQ08 + PQ10 + PQ14 + PQ11 + PQ12 + PQ13 + PQ16 + PQ15 + PQ17 + PQ18 + PQ19
SALES =~ SQ08 +  SQ07 + SQ09 + SQ10 + SQ11 + SQ12 + SQ13 + SQ14
+ SQ18 + SQ15 + SQ16 + SQ17 + SQ19 + SQ20 + SQ21 + SQ22
+ SQ24 + SQ23 + SQ25 + SQ26 + SQ27 + SQ28 + SQ29 + SQ31 + SQ32'
```

```{r}
PALS_SALESfit2 <- cfa(latents.model2, data =PALS_SALES)#standard fit
summary(PALS_SALESfit2) #to view summary of the fit
partable(PALS_SALESfit2) # to have the summary of parameters converted to a dataframe
vartable(PALS_SALESfit2) # to have the summary of variables converted to a dataframe
parameterestimates(PALS_SALESfit2) #parameterEstimates() includes the estimates, standard errors, z value, p value, and 95% CIs for all model parameters.
summary(PALS_SALESfit2,fit.measures = TRUE)
```

Model2 fit indices: 

User Model versus Baseline Model:

  Comparative Fit Index (CFI)                    0.595
  Tucker-Lewis Index (TLI)                       0.575
  
#Model3:Putting the common constructs together (regardless of the tool)

5 factor model: Putting MG & SE together, differentiating between Perf App and Avoidance goals.
```{r}
latents.model3 <- 'MasteryGoals =~ PQ02 + PQ01  + PQ03 + PQ04 + PQ05+ SQ24 + SQ23 + SQ25 + SQ26 + SQ27 + SQ28 + SQ29 + SQ31 + SQ32 
PerfAppGoals =~  PQ09 + PQ06 + PQ07 + PQ08 + PQ10
PerfAvGoals =~ PQ14 + PQ11 + PQ12 + PQ13 
SelfEfficacy =~ PQ16 + PQ15 + PQ17 + PQ18 + PQ19 + SQ08 +  SQ07 + SQ09 + SQ10 + SQ11 + SQ12 + SQ13 + SQ14
TaskValue =~ SQ18 + SQ15 + SQ16 + SQ17 + SQ19 + SQ20 + SQ21 + SQ22'
```

```{r}
PALS_SALESfit3 <- cfa(latents.model3, data =PALS_SALES)#standard fit
summary(PALS_SALESfit3) #to view summary of the fit
partable(PALS_SALESfit3) # to have the summary of parameters converted to a dataframe
vartable(PALS_SALESfit3) # to have the summary of variables converted to a dataframe
parameterestimates(PALS_SALESfit3) #parameterEstimates() includes the estimates, standard errors, z value, p value, and 95% CIs for all model parameters.
summary(PALS_SALESfit3,fit.measures = TRUE)
```

Model3 fit indices (improved)

User Model versus Baseline Model:

  Comparative Fit Index (CFI)                    0.768
  Tucker-Lewis Index (TLI)                       0.754
Root Mean Square Error of Approximation:

  RMSEA                                          0.073
  
#Model4: Same as model3, but combining peformance goals in one factor: 4 factor model

```{r}
latents.model4 <- 'MasteryGoals =~ PQ02 + PQ01  + PQ03 + PQ04 + PQ05+ SQ24 + SQ23 + SQ25 + SQ26 + SQ27 + SQ28 + SQ29 + SQ31 + SQ32 
PerfGoals =~  PQ09 + PQ06 + PQ07 + PQ08 + PQ10 + PQ14 + PQ11 + PQ12 + PQ13 
SelfEfficacy =~ PQ16 + PQ15 + PQ17 + PQ18 + PQ19 + SQ08 +  SQ07 + SQ09 + SQ10 + SQ11 + SQ12 + SQ13 + SQ14
TaskValue =~ SQ18 + SQ15 + SQ16 + SQ17 + SQ19 + SQ20 + SQ21 + SQ22'
```

```{r}
PALS_SALESfit4 <- cfa(latents.model4, data =PALS_SALES)#standard fit
summary(PALS_SALESfit4) #to view summary of the fit
partable(PALS_SALESfit4) # to have the summary of parameters converted to a dataframe
vartable(PALS_SALESfit4) # to have the summary of variables converted to a dataframe
parameterestimates(PALS_SALESfit4) #parameterEstimates() includes the estimates, standard errors, z value, p value, and 95% CIs for all model parameters.
summary(PALS_SALESfit4,fit.measures = TRUE)
```
Model4 Fit indices

User Model versus Baseline Model:

  Comparative Fit Index (CFI)                    0.752
  Tucker-Lewis Index (TLI)                       0.738

The fit of this model is lower than the 4 factor model.

#Model5, putting each instrument as separate

```{r}
latents.model5 <- 'MasteryGoals_P =~ PQ02 + PQ01  + PQ03 + PQ04 + PQ05
MasteryGoals_S =~ SQ24 + SQ23 + SQ25 + SQ26 + SQ27 + SQ28 + SQ29 + SQ31 + SQ32 
PerfGoals =~  PQ09 + PQ06 + PQ07 + PQ08 + PQ10 + PQ14 + PQ11 + PQ12 + PQ13 
SelfEfficacy_P =~ PQ16 + PQ15 + PQ17 + PQ18 + PQ19 
SelfEfficacy_S =~ SQ08 +  SQ07 + SQ09 + SQ10 + SQ11 + SQ12 + SQ13 + SQ14
TaskValue =~ SQ18 + SQ15 + SQ16 + SQ17 + SQ19 + SQ20 + SQ21 + SQ22'
```


```{r}
PALS_SALESfit5 <- cfa(latents.model5, data =PALS_SALES)#standard fit
summary(PALS_SALESfit5) #to view summary of the fit
partable(PALS_SALESfit5) # to have the summary of parameters converted to a dataframe
vartable(PALS_SALESfit5) # to have the summary of variables converted to a dataframe
parameterestimates(PALS_SALESfit5) #parameterEstimates() includes the estimates, standard errors, z value, p value, and 95% CIs for all model parameters.
summary(PALS_SALESfit5,fit.measures = TRUE)
```

Model5 fit indices

User Model versus Baseline Model:

  Comparative Fit Index (CFI)                    0.816
  Tucker-Lewis Index (TLI)                       0.804
  Root Mean Square Error of Approximation:

  RMSEA                                          0.065



#Appendix
PALS
```{r}
latents.model3 <- 'MasteryGoals =~ PQ02 + PQ01  + PQ03 + PQ04 + PQ05
PerfAppGoals =~  PQ09 + PQ06 + PQ07 + PQ08 + PQ10
PerfAvGoals =~ PQ14 + PQ11 + PQ12 + PQ13 
SelfEfficacy =~ PQ16 + PQ15 + PQ17 + PQ18 + PQ19
```

SALES

SelfEfficacy =~ SQ08 +  SQ07 + SQ09 + SQ10 + SQ11 + SQ12 + SQ13 + SQ14
TaskValue =~ SQ18 + SQ15 + SQ16 + SQ17 + SQ19 + SQ20 + SQ21 + Q22
MasteryGoals =~ SQ24 + SQ23 + SQ25 + SQ26 + SQ27 + SQ28 + SQ29 + SQ31 + SQ32'
'
```{r}

```

